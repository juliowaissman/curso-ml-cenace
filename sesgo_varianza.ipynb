{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ca4b77-0fab-41a3-ba0c-b0a93309cd79",
   "metadata": {},
   "source": [
    "<center>\n",
    "<p><img src=\"https://www.gob.mx/cms/uploads/image/file/179499/outstanding_quienes-somos.jpg\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "# Curso *Machine Learning con uso de pandas, scikit learn y libretas jupyter*\n",
    "\n",
    "# Relación entre sesgo y varianza\n",
    "\n",
    "\n",
    "<p> Julio Waissman Vilanova </p>\n",
    "<p>\n",
    "<img src=\"https://identidadbuho.unison.mx/wp-content/uploads/2019/06/letragrama-cmyk-72.jpg\" width=\"80\">\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab0a98-63a1-4985-8b5e-91892d1ef5ea",
   "metadata": {},
   "source": [
    "# Planteamiento del problema\n",
    "\n",
    "Vamos a asumir que tenemos una función desconocida para el que hace una regresión, pero conocida por nosotros (haciendo trampa). La función es \n",
    "\n",
    "$$y = \\sin(\\pi x),$$\n",
    "\n",
    "donde $x \\in [-1, 1]$.\n",
    "\n",
    "La función se vería como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8b5ad-ac8e-41ee-9ec4-9c49ede0825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(np.pi * x)\n",
    "\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, y)\n",
    "    plt.title(\"La función como si la conocieramos\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c055ef-55d3-400b-aeab-e34aeba028bd",
   "metadata": {},
   "source": [
    "Pero el que está clasificando no sabe eso, al el solo le vamos a dar *dos valores de (x, y) seleccionados en forma aleatoria*. \n",
    "\n",
    "Con estos dos puntos solamente, el pobre tiene que hacer un modelo de regresión. \n",
    "\n",
    "Primero y antes que nada, vamos a definir un criterio de error, el cual (haciendo trampa) lo vamos a calcular usando la función que nosotros si conocemos. \n",
    "\n",
    "El pobre estimador solo tiene dos valores para hacer el aprendizaje, pero con el modelo aprendido, nosotros  vamos a aproximar el error en muestra con **todos** los 1000 datos que ya tenemos:\n",
    "\n",
    "$$\n",
    "E_{out} \\approx \\frac{1}{1000} \\sum_{i=1}^{1000}{(y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Programa la función que aproxima el error fuera de muestra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfd96d-24dd-4dd0-a742-eda8f5b93c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_estimado(y, y_estimada):\n",
    "    \"\"\"\n",
    "    Calcula el error fuera de muestra con el criterio MSE\n",
    "    \n",
    "    y: un ndarray de una dimensión\n",
    "    y_estimada: un ndarray de una dimensión\n",
    "    \n",
    "    \"\"\"    \n",
    "    error = ---Inserta aqui tu código---\n",
    "    \n",
    "    return error\n",
    "\n",
    "assert error_estimado(np.array([1, 2, 3, 4]), np.array([1, 2, 3, 4])) == 0.\n",
    "\n",
    "assert error_estimado(np.array([1, 2, 3, 4]), np.array([4, 3, 2, 1])) == 5.\n",
    "\n",
    "assert error_estimado(np.array([1, 2, 3, 4]), np.ones(4)) == 3.5\n",
    "\n",
    "print(\"Ahí vamos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074a3b0-4c4f-4873-b5ad-bdf713de08fd",
   "metadata": {},
   "source": [
    "# La hipótesis más simple\n",
    "\n",
    "Ahora vams con el compa que anda aprendiendo, le vamos a dar un conjunto de hipótesis, las más sencillas posibles (recuerda que tiene que estimar una regresión con solo dos números)\n",
    "\n",
    "La hipótesis va a ser entonces:\n",
    "\n",
    "$$h_0(x) = b$$\n",
    "\n",
    "Osea que va a estimar una constante. \n",
    "\n",
    "¿Y cual va a ser el algoritmo de entrenamiento/aprendizaje/optimización? Pues el único posible.\n",
    "\n",
    "Esto es, si tenemos dos ejemplos $\\{(x_1, y_1), (x_2, y_2)\\}, el aprendizaje solo podria calcularse como:\n",
    "\n",
    "$$b = \\frac{y_1 + y_2}{2}$$,\n",
    "\n",
    "Esto es, solo tenemos dos puntos, y aprendemos un modelo donde el valor estimado $\\hat{y}$ va a ser el mismo, independientemente del valor de $x$.\n",
    "\n",
    "Vamos entonces haciendo al algoritmo de aprendizaje, y el modelo de estimción:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785689e-ce99-4aa6-8daa-2c17c5619db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_h0(x_1, x_2, y_1, y_2):\n",
    "    \"\"\"\n",
    "    Calcula el valor de los parámetros del modelo (en este caso b)\n",
    "    \n",
    "    x_1, x_2, valores entre -1 y 1 de dos ejemplos de x para el aprendizaje\n",
    "    y_1 y y_2, valores entre -1 y 1 de los valores correspondientes en y de x_1 y x_2 respectivamente\n",
    "    \n",
    "    \"\"\"\n",
    "    b = ---Inserta aqui tu código---\n",
    "    \n",
    "    return b\n",
    "\n",
    "def estimador_h0(b, x):\n",
    "    \"\"\"\n",
    "    Estima los valores de y\n",
    "    \n",
    "    b : parámetro del modelo\n",
    "    x : ndarray con entradas\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    y_estimada = ---Inserta aqui tu código---\n",
    "    \n",
    "    return y_estimada\n",
    "\n",
    "\n",
    "assert abs(entrenamiento_h0(-.5, .3, .2, .4) - 0.3) < 1e-6\n",
    "assert abs(entrenamiento_h0(-.1, .1, .3, .3) - 0.3) < 1e-6\n",
    "\n",
    "assert np.sum(estimador_h0(0, np.linspace(-1,1,1000))) < 1e-6\n",
    "assert (np.sum(estimador_h0(.7, np.linspace(-1,1,1000))) - 700) < 1e-6\n",
    "\n",
    "print(\"A seguirle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8de69c-3c15-4f1c-96fe-83ee3f0c3318",
   "metadata": {},
   "source": [
    "Y ahora vamos a calcular el error de aprendizaje para un par de ejemplos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ea41c-5c8a-4832-a56a-bf9413b477e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 2 * np.random.random() -1\n",
    "x2 = 2 * np.random.random() -1\n",
    "\n",
    "y1 = np.sin(np.pi * x1)\n",
    "y2 = np.sin(np.pi * x2)\n",
    "\n",
    "b = entrenamiento_h0(x1, x2, y1, y2)\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(np.pi * x)\n",
    "y_estimada = estimador_h0(b, x)\n",
    "\n",
    "E_out = error_estimado(y, y_estimada)\n",
    "\n",
    "print(\"Tenemos dos ejemplos para el entrenamiento: \")\n",
    "print(f\"\\t x1 = {x1}, y1 = {y1}\")\n",
    "print(f\"\\t x2 = {x2}, y1 = {y2}\")\n",
    "print(f\"Con un modelo donde b = {b}\")\n",
    "print(f\"y el error fuera de  muestra se estimo como {E_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb71b97-1969-4e2f-ac55-65f117085a6c",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer lo mismo pero 10000 veces y vamos a calcular 10000 estimaciones. Vamos a calcular la varianza entre estimaciones y vamos a sacar una estimación promedio para calcular el error de la salida real con el valor promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23958f23-d42e-4e3c-8fbe-3c1db0b1027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 10000)\n",
    "y = np.sin(np.pi * x)\n",
    "\n",
    "y_estimada = []\n",
    "for _ in range(10000):\n",
    "    x1 = 2 * np.random.random() -1\n",
    "    x2 = 2 * np.random.random() -1\n",
    "\n",
    "    y1 = np.sin(np.pi * x1)\n",
    "    y2 = np.sin(np.pi * x2)\n",
    "\n",
    "    b = entrenamiento_h0(x1, x2, y1, y2)\n",
    "    y_estimada.append(estimador_h0(b, x))\n",
    "\n",
    "y_est = np.vstack(y_estimada)\n",
    "\n",
    "var = y_est.var()\n",
    "\n",
    "y_est_media = y_est.mean(axis=0)\n",
    "sesgo = error_estimado(y, y_est_media)\n",
    "\n",
    "print(f\"Este modelo presento un sesgo de {sesgo} y una varianza de {var}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5976b5-971b-4f9c-8e52-454186333848",
   "metadata": {},
   "source": [
    "# La hipótesis más compleja\n",
    "\n",
    "Bueno eso de compleja compleja, pues no, pero la mñas complejo que se puede hacer con dos pobres ejemplos para el aprendizaje.\n",
    "\n",
    "La hipótesis va a ser entonces:\n",
    "\n",
    "$$h_1(x) = ax + b$$\n",
    "\n",
    "Una linea recta, la cual pasa *exactamente por los dos ejemplos*, con un error en muestra de 0 (aprendizaje perfecto). \n",
    "\n",
    "¿Y cual va a ser el algoritmo de entrenamiento/aprendizaje/optimización? Pues el único posible otra vez.\n",
    "\n",
    "Esto es, si tenemos dos ejemplos $\\{(x_1, y_1), (x_2, y_2)\\}, el aprendizaje solo podria calcularse como:\n",
    "\n",
    "$$a = \\frac{y_2 - y_1}{x_2 - x_1}$$\n",
    "\n",
    "$$b = y_1 - a x_1$$,\n",
    "\n",
    "Si mis recuerdos de la secundaria no me fallan.\n",
    "\n",
    "Vamos entonces haciendo al algoritmo de aprendizaje, y el modelo de estimción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cd193-7bb1-44ff-8160-e1367c38b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_h1(x_1, x_2, y_1, y_2):\n",
    "    \"\"\"\n",
    "    Calcula el valor de los parámetros del modelo (en este caso a y b)\n",
    "    \n",
    "    x_1, x_2, valores entre -1 y 1 de dos ejemplos de x para el aprendizaje\n",
    "    y_1 y y_2, valores entre -1 y 1 de los valores correspondientes en y de x_1 y x_2 respectivamente\n",
    "    \n",
    "    \"\"\"\n",
    "    a = ---Inserta aqui tu código---\n",
    "    b = ---Inserta aqui tu código---\n",
    "    \n",
    "    return a, b\n",
    "\n",
    "def estimador_h1(a, b, x):\n",
    "    \"\"\"\n",
    "    Estima los valores de y\n",
    "    \n",
    "    b : parámetro del modelo\n",
    "    x : ndarray con entradas\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    y_estimada = ---Inserta aqui tu código---\n",
    "    \n",
    "    return y_estimada\n",
    "\n",
    "\n",
    "assert(entrenamiento_h1(-.5, .5, -.5, .5)) == (1.0, 0.0)\n",
    "assert(entrenamiento_h1(-.5, .5, .5, -.5)) == (-1.0, 0.0)\n",
    "assert(entrenamiento_h1(-.5, .5, .3, .3)) == (0.0, 0.3)\n",
    "assert np.mean(estimador_h1(1, 0, np.linspace(-1,1,1000))) == 0.0\n",
    "assert (np.mean(estimador_h1(.1, 0.3, np.linspace(-1,1,1000))) - 0.3) < 1e-6\n",
    "\n",
    "print(\"A seguirle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15635c-7b18-4056-901d-c62ff0d2ee8d",
   "metadata": {},
   "source": [
    "Y ahora vamos a calcular el error de aprendizaje para un par de ejemplos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295f987-1f0f-4038-a7bf-2a9099384d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 2 * np.random.random() -1\n",
    "x2 = 2 * np.random.random() -1\n",
    "\n",
    "y1 = np.sin(np.pi * x1)\n",
    "y2 = np.sin(np.pi * x2)\n",
    "\n",
    "a, b = entrenamiento_h1(x1, x2, y1, y2)\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(np.pi * x)\n",
    "y_estimada = estimador_h1(a, b, x)\n",
    "\n",
    "E_out = error_estimado(y, y_estimada)\n",
    "\n",
    "print(\"Tenemos dos ejemplos para el entrenamiento: \")\n",
    "print(f\"\\t x1 = {x1}, y1 = {y1}\")\n",
    "print(f\"\\t x2 = {x2}, y1 = {y2}\")\n",
    "print(f\"Con un modelo donde a = {a} y b = {b}\")\n",
    "print(f\"y el error fuera de  muestra se estimo como {E_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0b18f-2898-4da3-98bf-82c441e4d058",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer lo mismo que en el modelo anterior para calcular el sesgo y la varinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d108f6-d23e-4742-9715-b1bfc87861dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(np.pi * x)\n",
    "\n",
    "y_estimada = []\n",
    "for _ in range(10000):\n",
    "    x1 = 2 * np.random.random() -1\n",
    "    x2 = 2 * np.random.random() -1\n",
    "\n",
    "    y1 = np.sin(np.pi * x1)\n",
    "    y2 = np.sin(np.pi * x2)\n",
    "\n",
    "    a, b = entrenamiento_h1(x1, x2, y1, y2)\n",
    "    y_estimada.append(estimador_h1(a, b, x))\n",
    "\n",
    "y_est = np.vstack(y_estimada)\n",
    "\n",
    "var = y_est.var()\n",
    "\n",
    "y_est_media = y_est.mean(axis=0)\n",
    "sesgo = error_estimado(y, y_est_media)\n",
    "\n",
    "print(f\"Este modelo presento un sesgo de {sesgo} y una varianza de {var}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29172a5a-e13b-4d39-9fc9-7e2eecdc6087",
   "metadata": {},
   "source": [
    "# Comparando\n",
    "\n",
    "1. ¿Como fue el sesgo y la varianza de cada modelo?\n",
    "2. ¿Que significa tener un valor de sesgo alto o bajo?\n",
    "3. ¿Qué significa tener un valor de varianza alto o bajo?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
